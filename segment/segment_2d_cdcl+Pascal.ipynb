{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from configobj import ConfigObj\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def config_reader():\n",
        "    config = ConfigObj('config')\n",
        "\n",
        "    param = config['param']\n",
        "    model_id = param['modelID']\n",
        "    model = config['models'][model_id]\n",
        "    model['boxsize'] = int(model['boxsize'])\n",
        "    model['stride'] = int(model['stride'])\n",
        "    model['padValue'] = int(model['padValue'])\n",
        "    #param['starting_range'] = float(param['starting_range'])\n",
        "    #param['ending_range'] = float(param['ending_range'])\n",
        "    param['octave'] = int(param['octave'])\n",
        "    param['use_gpu'] = int(param['use_gpu'])\n",
        "    param['starting_range'] = float(param['starting_range'])\n",
        "    param['ending_range'] = float(param['ending_range'])\n",
        "    param['scale_search'] = map(float, param['scale_search'])\n",
        "    param['thre1'] = float(param['thre1'])\n",
        "    param['thre2'] = float(param['thre2'])\n",
        "    param['thre3'] = float(param['thre3'])\n",
        "    param['mid_num'] = int(param['mid_num'])\n",
        "    param['min_num'] = int(param['min_num'])\n",
        "    param['crop_ratio'] = float(param['crop_ratio'])\n",
        "    param['bbox_ratio'] = float(param['bbox_ratio'])\n",
        "    param['GPUdeviceNumber'] = int(param['GPUdeviceNumber'])\n",
        "\n",
        "    return param, model"
      ],
      "metadata": {
        "id": "FBEas1JOJzDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-gAJ7S18f6F"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#part_ids = [ 0,  2,  4,  5,  6,  8, 13, 14, 16, 17, 18, 19, 20, 21, 24]\n",
        "# the order is: (left right flipped)\n",
        "# background, head, torso, left upper arm ,right upper arm, left forearm, right forearm,\n",
        "#  left hand, right hand, left thigh, right thigh, left shank, right shank, left foot, right foot\n",
        "part_ids = [0, 13, 2, 5, 8, 19, 20, 4, 24, 18, 6, 21, 16, 14, 17]\n",
        "\n",
        "png_idx = [0, 14, 1, 11, 10, 13, 12, 2, 3, 6, 7, 8, 9, 5, 4]\n",
        "\n",
        "\n",
        "def human_seg_spread_channel(human_seg_map):\n",
        "    x = human_seg_map // 127\n",
        "    x = x * np.array([9, 3, 1])\n",
        "    x = np.add.reduce(x, 2)\n",
        "    res = []\n",
        "    for i in part_ids:\n",
        "        res.append((x == i))\n",
        "    res = np.stack(res, axis=-1)\n",
        "    return res.astype(np.float32)\n",
        "\n",
        "def human_seg_combine_channel(human_seg_split_map):\n",
        "    segmap = np.add.reduce(human_seg_split_map * np.array(png_idx), 2)\n",
        "    return np.stack([segmap], axis=-1).astype(np.uint8)\n",
        "\n",
        "def human_seg_combine_argmax(human_seg_argmax_map):\n",
        "    onehot = np.stack([(human_seg_argmax_map == i).astype(np.uint8) for i in range(15)], axis=-1)\n",
        "    return human_seg_combine_channel(onehot)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from io import StringIO\n",
        "import PIL.Image\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def showBGRimage(a, fmt='jpeg'):\n",
        "    a = np.uint8(np.clip(a, 0, 255))\n",
        "    a[:,:,[0,2]] = a[:,:,[2,0]] # for B,G,R order\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))\n",
        "\n",
        "def showmap(a, fmt='png'):\n",
        "    a = np.uint8(np.clip(a, 0, 255))\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))\n",
        "\n",
        "def getJetColor(v, vmin, vmax):\n",
        "    c = np.zeros((3))\n",
        "    if (v < vmin):\n",
        "        v = vmin\n",
        "    if (v > vmax):\n",
        "        v = vmax\n",
        "    dv = vmax - vmin\n",
        "    if (v < (vmin + 0.125 * dv)):\n",
        "        c[0] = 256 * (0.5 + (v * 4)) #B: 0.5 ~ 1\n",
        "    elif (v < (vmin + 0.375 * dv)):\n",
        "        c[0] = 255\n",
        "        c[1] = 256 * (v - 0.125) * 4 #G: 0 ~ 1\n",
        "    elif (v < (vmin + 0.625 * dv)):\n",
        "        c[0] = 256 * (-4 * v + 2.5)  #B: 1 ~ 0\n",
        "        c[1] = 255\n",
        "        c[2] = 256 * (4 * (v - 0.375)) #R: 0 ~ 1\n",
        "    elif (v < (vmin + 0.875 * dv)):\n",
        "        c[1] = 256 * (-4 * v + 3.5)  #G: 1 ~ 0\n",
        "        c[2] = 255\n",
        "    else:\n",
        "        c[2] = 256 * (-4 * v + 4.5) #R: 1 ~ 0.5\n",
        "    return c\n",
        "\n",
        "def colorize(gray_img):\n",
        "    out = np.zeros(gray_img.shape + (3,))\n",
        "    for y in range(out.shape[0]):\n",
        "        for x in range(out.shape[1]):\n",
        "            out[y,x,:] = getJetColor(gray_img[y,x], 0, 1)\n",
        "    return out\n",
        "\n",
        "def padRightDownCorner(img, stride, padValue):\n",
        "    h = img.shape[0]\n",
        "    w = img.shape[1]\n",
        "\n",
        "    pad = 4 * [None]\n",
        "    pad[0] = 0 # up\n",
        "    pad[1] = 0 # left\n",
        "    pad[2] = 0 if (h%stride==0) else stride - (h % stride) # down\n",
        "    pad[3] = 0 if (w%stride==0) else stride - (w % stride) # right\n",
        "\n",
        "    img_padded = img\n",
        "    pad_up = np.tile(img_padded[0:1,:,:]*0 + padValue, (pad[0], 1, 1))\n",
        "    img_padded = np.concatenate((pad_up, img_padded), axis=0)\n",
        "    pad_left = np.tile(img_padded[:,0:1,:]*0 + padValue, (1, pad[1], 1))\n",
        "    img_padded = np.concatenate((pad_left, img_padded), axis=1)\n",
        "    pad_down = np.tile(img_padded[-2:-1,:,:]*0 + padValue, (pad[2], 1, 1))\n",
        "    img_padded = np.concatenate((img_padded, pad_down), axis=0)\n",
        "    pad_right = np.tile(img_padded[:,-2:-1,:]*0 + padValue, (1, pad[3], 1))\n",
        "    img_padded = np.concatenate((img_padded, pad_right), axis=1)\n",
        "\n",
        "    return img_padded, pad"
      ],
      "metadata": {
        "id": "D7pqbYFB9N1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resize_images(*args, **kwargs):\n",
        "    return tf.image.resize_images(*args, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "class DeformableDeConv(keras.layers.Layer):\n",
        "\tdef __init__(self, kernel_size, stride, filter_num, *args, **kwargs):\n",
        "\t\tself.stride = stride\n",
        "\t\tself.filter_num = filter_num\n",
        "\t\tself.kernel_size =kernel_size\n",
        "\t\tsuper(DeformableDeConv, self).__init__(*args,**kwargs)\n",
        "\n",
        "\tdef build(self, input_shape):\n",
        "\t\t# Create a trainable weight variable for this layer.\n",
        "\t\tin_filters = self.filter_num\n",
        "\t\tout_filters = self.filter_num\n",
        "\t\tself.kernel = self.add_weight(name='kernel',\n",
        "\t\t\t\t\t\t\t\t\t  shape=[self.kernel_size, self.kernel_size, out_filters, in_filters],\n",
        "\t\t\t\t\t\t\t\t\t  initializer='uniform',\n",
        "\t\t\t\t\t\t\t\t\t  trainable=True)\n",
        "\n",
        "\t\tsuper(DeformableDeConv, self).build(input_shape)\n",
        "\n",
        "\tdef call(self, inputs, **kwargs):\n",
        "\t\tsource, target = inputs\n",
        "\t\ttarget_shape = K.shape(target)\n",
        "\t\treturn tf.nn.conv2d_transpose(source,\n",
        "\t\t\t\t\t\t\t\t\tself.kernel,\n",
        "\t\t\t\t\t\t\t\t\toutput_shape=target_shape,\n",
        "\t\t\t\t\t\t\t\t\tstrides=self.stride,\n",
        "\t\t\t\t\t\t\t\t\tpadding='SAME',\n",
        "\t\t\t\t\t\t\t\t\tdata_format='NHWC')\n",
        "\tdef get_config(self):\n",
        "\t\tconfig = {'kernel_size': self.kernel_size, 'stride': self.stride, 'filter_num': self.filter_num}\n",
        "\t\tbase_config = super(DeformableDeConv, self).get_config()\n",
        "\t\treturn dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class UpsampleLike(keras.layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        source, target = inputs\n",
        "        target_shape = K.shape(target)\n",
        "        return resize_images(source, (target_shape[1], target_shape[2]))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0],) + input_shape[1][1:3] + (input_shape[0][-1],)\n",
        "\n",
        "class ScalingLayer(keras.layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        source, target = inputs\n",
        "        target_shape = K.shape(target)\n",
        "        return resize_images(source, (target_shape[1], target_shape[2]))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0],) + input_shape[1][1:3] + (input_shape[0][-1],)"
      ],
      "metadata": {
        "id": "0o_GsMbQ8-Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Concatenate, Multiply\n",
        "from keras.layers import Activation, Input, Lambda\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import RandomNormal, Constant\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Add, Conv2DTranspose\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "from tensorflow.python.keras.utils import layer_utils\n",
        "from tensorflow.keras.utils import get_file\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "# from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from tensorflow.keras.utils import get_source_inputs\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras import initializers\n",
        "from keras.layers import add\n",
        "\n",
        "import code\n",
        "import keras.backend as K\n",
        "\n",
        "stages = 1\n",
        "np_branch1 = 38\n",
        "np_branch2 = 19\n",
        "np_branch3 = 15\n",
        "\n",
        "\n",
        "class Scale(Layer):\n",
        "    \"\"\"Custom Layer for ResNet used for BatchNormalization.\n",
        "\n",
        "    Learns a set of weights and biases used for scaling the input data.\n",
        "    the output consists simply in an element-wise multiplication of the input\n",
        "    and a sum of a set of constants:\n",
        "\n",
        "        out = in * gamma + beta,\n",
        "\n",
        "    where 'gamma' and 'beta' are the weights and biases larned.\n",
        "\n",
        "    Keyword arguments:\n",
        "    axis -- integer, axis along which to normalize in mode 0. For instance,\n",
        "        if your input tensor has shape (samples, channels, rows, cols),\n",
        "        set axis to 1 to normalize per feature map (channels axis).\n",
        "    momentum -- momentum in the computation of the exponential average\n",
        "        of the mean and standard deviation of the data, for\n",
        "        feature-wise normalization.\n",
        "    weights -- Initialization weights.\n",
        "        List of 2 Numpy arrays, with shapes:\n",
        "        `[(input_shape,), (input_shape,)]`\n",
        "    beta_init -- name of initialization function for shift parameter\n",
        "        (see [initializers](../initializers.md)), or alternatively,\n",
        "        Theano/TensorFlow function to use for weights initialization.\n",
        "        This parameter is only relevant if you don't pass a `weights` argument.\n",
        "    gamma_init -- name of initialization function for scale parameter (see\n",
        "        [initializers](../initializers.md)), or alternatively,\n",
        "        Theano/TensorFlow function to use for weights initialization.\n",
        "        This parameter is only relevant if you don't pass a `weights` argument.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
        "        self.momentum = momentum\n",
        "        self.axis = axis\n",
        "        self.beta_init = initializers.get(beta_init)\n",
        "        self.gamma_init = initializers.get(gamma_init)\n",
        "        self.initial_weights = weights\n",
        "        super(Scale, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        shape = (int(input_shape[self.axis]),)\n",
        "\n",
        "        self.gamma = self.add_weight(shape=shape, initializer=self.gamma_init, name='%s_gamma' % self.name)\n",
        "        self.beta = self.add_weight(shape=shape, initializer=self.beta_init, name='%s_beta' % self.name)\n",
        "\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
        "        base_config = super(Scale, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def mytransform(source, ref_tensor):\n",
        "    target_shape = K.shape(ref_tensor)\n",
        "    source_shape = K.shape(source)\n",
        "    return K.resize_images(source, target_shape[1]/source_shape[1],target_shape[2]/source_shape[2], \"channels_last\")\n",
        "    # return tensorflow.image.resize_images(source, (target_shape[1],target_shape[2]))\n",
        "\n",
        "def relu(x): return Activation('relu')(x)\n",
        "def sigmoid(x): return Activation('sigmoid')(x)\n",
        "\n",
        "def conv(x, nf, ks, name, weight_decay):\n",
        "    kernel_reg = l2(weight_decay[0]) if weight_decay else None\n",
        "    bias_reg = l2(weight_decay[1]) if weight_decay else None\n",
        "\n",
        "    x = Conv2D(nf, (ks, ks), padding='same', name=name,\n",
        "               kernel_regularizer=kernel_reg,\n",
        "               bias_regularizer=bias_reg,\n",
        "               kernel_initializer=RandomNormal(stddev=0.01),\n",
        "               bias_initializer=Constant(0.0))(x)\n",
        "    return x\n",
        "\n",
        "def conv_stride(x, nf, ks, name, weight_decay, stride=(2,2)):\n",
        "    kernel_reg = l2(weight_decay[0]) if weight_decay else None\n",
        "    bias_reg = l2(weight_decay[1]) if weight_decay else None\n",
        "\n",
        "    x = Conv2D(nf, (ks, ks), padding='same', name=name, strides=stride,\n",
        "               kernel_regularizer=kernel_reg,\n",
        "               bias_regularizer=bias_reg,\n",
        "               kernel_initializer=RandomNormal(stddev=0.01),\n",
        "               bias_initializer=Constant(0.0))(x)\n",
        "    return x\n",
        "\n",
        "def pooling(x, ks, st, name):\n",
        "    x = MaxPooling2D((ks, ks), strides=(st, st), name=name)(x)\n",
        "    return x\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity_block is the block that has no conv layer at shortcut\n",
        "\n",
        "    Keyword arguments\n",
        "    input_tensor -- input tensor\n",
        "    kernel_size -- defualt 3, the kernel size of middle conv layer at main path\n",
        "    filters -- list of integers, the nb_filters of 3 conv layer at main path\n",
        "    stage -- integer, current stage label, used for generating layer names\n",
        "    block -- 'a','b'..., current block label, used for generating layer names\n",
        "\n",
        "    \"\"\"\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a',use_bias=False)(input_tensor)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2a')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
        "\n",
        "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),name=conv_name_base + '2b', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2b')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
        "\n",
        "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c',use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2c')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
        "\n",
        "    x = add([x, input_tensor], name='res' + str(stage) + block)\n",
        "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
        "\n",
        "    Keyword arguments:\n",
        "    input_tensor -- input tensor\n",
        "    kernel_size -- defualt 3, the kernel size of middle conv layer at main path\n",
        "    filters -- list of integers, the nb_filters of 3 conv layer at main path\n",
        "    stage -- integer, current stage label, used for generating layer names\n",
        "    block -- 'a','b'..., current block label, used for generating layer names\n",
        "\n",
        "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
        "    And the shortcut should have subsample=(2,2) as well\n",
        "\n",
        "    \"\"\"\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(nb_filter1, (1, 1), strides=strides,name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2a')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
        "\n",
        "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),name=conv_name_base + '2b', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2b')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
        "\n",
        "    x = Conv2D(nb_filter3, (1, 1),name=conv_name_base + '2c', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '2c')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,name=conv_name_base + '1', use_bias=False)(input_tensor)\n",
        "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis,name=bn_name_base + '1')(shortcut)\n",
        "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
        "\n",
        "    x = add([x, shortcut], name='res' + str(stage) + block)\n",
        "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet101_graph(img_input, weight_decay):\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    branch = 0\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    # C1 --------------------------------------------------\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
        "    x = Activation('relu', name='conv1_relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    C1 = x\n",
        "\n",
        "    # C2 --------------------------------------------------\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    C2 = x\n",
        "\n",
        "    # C3 --------------------------------------------------\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    for i in range(1, 3):\n",
        "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b' + str(i))\n",
        "    C3 = x\n",
        "\n",
        "    # C4 --------------------------------------------------\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    for i in range(1, 23):\n",
        "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b' + str(i))\n",
        "    C4 = x\n",
        "\n",
        "    # C5 ---------------------------------------------------\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    C5 = x\n",
        "\n",
        "    return C1, C2, C3, C4, C5\n",
        "\n",
        "\n",
        "def create_pyramid_features(C1, C2, C3, C4, C5, feature_size=256):\n",
        "    P5 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C5_reduced')(C5)\n",
        "    P4 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C4_reduced')(C4)\n",
        "    P3 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C3_reduced')(C3)\n",
        "    P2 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C2_reduced')(C2)\n",
        "    P1 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C1_reduced')(C1)\n",
        "\n",
        "    # upsample P5 to get P5_up1\n",
        "    P5_up1 = DeformableDeConv(name='P5_up1_deconv',\n",
        "                                             kernel_size=4,\n",
        "                                             stride=[1,2,2,1],\n",
        "                                             filter_num=feature_size)([P5,P4])\n",
        "    # upsample P5_up1 to get P5_up2\n",
        "    P5_up2 = DeformableDeConv(name='P5_up2_deconv',\n",
        "                                             kernel_size=4,\n",
        "                                             stride=[1,2,2,1],\n",
        "                                             filter_num=feature_size)([P5_up1,P3])\n",
        "    # upsample P4 to get P4_up1\n",
        "    P4_up1 = DeformableDeConv(name='P4_up1_deconv',\n",
        "                                             kernel_size=4,\n",
        "                                             stride=[1,2,2,1],\n",
        "                                             filter_num=feature_size)([P4,P3])\n",
        "\n",
        "    # downsample P1 to get P1_down1\n",
        "    P1_down1 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='P1_down1')(P1)\n",
        "    # downsample P1_down1 to get P1_down2\n",
        "    P1_down2 = Conv2D(feature_size, kernel_size=1, strides=2, padding='same', name='P1_down2')(P1_down1)\n",
        "    # downsample P2 to get P2_down\n",
        "    P2_down1 = Conv2D(feature_size, kernel_size=1, strides=2, padding='same', name='P2_down1')(P2)\n",
        "\n",
        "\n",
        "    P5_up2 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P5_up2_head')(P5_up2)\n",
        "    P5_up2 = relu(P5_up2)\n",
        "\n",
        "    P4_up1 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P4_up1_head')(P4_up1)\n",
        "    P4_up1 = relu(P4_up1)\n",
        "\n",
        "    P3 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P3_head')(P3)\n",
        "    P3 = relu(P3)\n",
        "\n",
        "    P2_down1 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P2_down1_head')(P2_down1)\n",
        "    P2_down1 = relu(P2_down1)\n",
        "\n",
        "    P1_down2 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P1_down2_head')(P1_down2)\n",
        "    P1_down2 = relu(P1_down2)\n",
        "\n",
        "\n",
        "    # Concatenate features at different levels\n",
        "    pyramid_feat = []\n",
        "    pyramid_feat.append(P5_up2)\n",
        "    pyramid_feat.append(P4_up1)\n",
        "    pyramid_feat.append(P3)\n",
        "    pyramid_feat.append(P2_down1)\n",
        "    pyramid_feat.append(P1_down2)\n",
        "    feats = Concatenate()(pyramid_feat)\n",
        "\n",
        "    return feats\n",
        "\n",
        "\n",
        "\n",
        "def stage1_block(x, num_p, branch, weight_decay):\n",
        "    # Block 1\n",
        "    x = conv(x, 512, 3, \"Mconv1_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 3, \"Mconv2_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 3, \"Mconv3_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 3, \"Mconv4_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 3, \"Mconv5_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 3, \"Mconv6_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 512, 1, \"Mconv7_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, num_p, 1, \"Mconv8_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def stage1_segmentation_block(x, num_p, branch, weight_decay):\n",
        "    # Block 1\n",
        "    x = conv(x, 256, 3, \"Mconv1_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 256, 3, \"Mconv2_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 256, 3, \"Mconv3_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 256, 3, \"Mconv4_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, 256, 1, \"Mconv5_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    x = relu(x)\n",
        "    x = conv(x, num_p, 1, \"Mconv6_stage1_L%d\" % branch, (weight_decay, 0))\n",
        "    #x = sigmoid(x)\n",
        "    x = Activation('softmax')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def apply_mask(x, mask1, mask2, mask3, num_p, stage, branch):\n",
        "    w_name = \"weight_stage%d_L%d\" % (stage, branch)\n",
        "    if num_p == np_branch1:\n",
        "        w = Multiply(name=w_name)([x, mask1])  # vec_weight\n",
        "    elif num_p == np_branch2:\n",
        "        w = Multiply(name=w_name)([x, mask2])  # vec_heat\n",
        "    elif num_p == np_branch3:\n",
        "        w = Multiply(name=w_name)([x, mask3])  # seg\n",
        "    else:\n",
        "        assert False, \"wrong number of layers num_p=%d \" % num_p\n",
        "    return w\n",
        "\n",
        "\n",
        "def get_training_model_resnet101(weight_decay, gpus=None):\n",
        "\n",
        "    img_input_shape = (None, None, 3)\n",
        "    vec_input_shape = (None, None, 38)\n",
        "    heat_input_shape = (None, None, 19)\n",
        "    seg_input_shape = (None, None, 15)\n",
        "\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    img_input = Input(shape=img_input_shape)\n",
        "    vec_weight_input = Input(shape=vec_input_shape)\n",
        "    heat_weight_input = Input(shape=heat_input_shape)\n",
        "    seg_weight_input = Input(shape=seg_input_shape)\n",
        "\n",
        "    inputs.append(img_input)\n",
        "    inputs.append(vec_weight_input)\n",
        "    inputs.append(heat_weight_input)\n",
        "    inputs.append(seg_weight_input)\n",
        "\n",
        "    # resnet101\n",
        "    C1, C2, C3, C4, C5 = ResNet101_graph(img_input, weight_decay)\n",
        "\n",
        "    stage0_out = create_pyramid_features(C1, C2, C3, C4, C5)\n",
        "\n",
        "    # Additional layers for learning multi-scale semantics\n",
        "    stage0_out = conv(stage0_out, 512, 3, \"pyramid_1_CPM\", (weight_decay, 0))\n",
        "    stage0_out = relu(stage0_out)\n",
        "    stage0_out = conv(stage0_out, 512, 3, \"pyramid_2_CPM\", (weight_decay, 0))\n",
        "    stage0_out = relu(stage0_out)\n",
        "\n",
        "    # stage 1 - branch 1 (PAF)\n",
        "    stage1_branch1_out = stage1_block(stage0_out, np_branch1, 1, weight_decay)\n",
        "    w1 = apply_mask(stage1_branch1_out, vec_weight_input, heat_weight_input, seg_weight_input, np_branch1, 1, 1)\n",
        "\n",
        "    # stage 1 - branch 2 (confidence maps)\n",
        "    stage1_branch2_out = stage1_block(stage0_out, np_branch2, 2, weight_decay)\n",
        "    w2 = apply_mask(stage1_branch2_out, vec_weight_input, heat_weight_input, seg_weight_input, np_branch2, 1, 2)\n",
        "\n",
        "    # stage 1 - branch 3 (semantic segmentation)\n",
        "    stage1_branch3_out = stage1_segmentation_block(stage0_out, np_branch3, 3, weight_decay)\n",
        "    w3 = apply_mask(stage1_branch3_out, vec_weight_input, heat_weight_input, seg_weight_input, np_branch3, 1, 3)\n",
        "\n",
        "    outputs.append(w1)\n",
        "    outputs.append(w2)\n",
        "    outputs.append(w3)\n",
        "\n",
        "\n",
        "    if gpus is None:\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "    else:\n",
        "        import tensorflow as tf\n",
        "        with tf.device('/cpu:0'): #this model will not be actually used, it's template\n",
        "            model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def get_testing_model_resnet101():\n",
        "\n",
        "    img_input_shape = (None, None, 3)\n",
        "\n",
        "    img_input = Input(shape=img_input_shape)\n",
        "\n",
        "    C1, C2, C3, C4, C5 = ResNet101_graph(img_input, None)\n",
        "\n",
        "    stage0_out = create_pyramid_features(C1, C2, C3, C4, C5)\n",
        "\n",
        "    # Additional layers for learning multi-scale semantics\n",
        "    stage0_out = conv(stage0_out, 512, 3, \"pyramid_1_CPM\", (None, 0))\n",
        "    stage0_out = relu(stage0_out)\n",
        "    stage0_out = conv(stage0_out, 512, 3, \"pyramid_2_CPM\", (None, 0))\n",
        "    stage0_out = relu(stage0_out)\n",
        "\n",
        "    # stage 1 - branch 1 (PAF)\n",
        "    stage1_branch1_out = stage1_block(stage0_out, np_branch1, 1, None)\n",
        "\n",
        "    # stage 1 - branch 2 (confidence maps)\n",
        "    stage1_branch2_out = stage1_block(stage0_out, np_branch2, 2, None)\n",
        "\n",
        "    # stage 1 - branch 3 (semantic segmentation)\n",
        "    stage1_branch3_out = stage1_segmentation_block(stage0_out, np_branch3, 3, None)\n",
        "\n",
        "\n",
        "    model = Model(inputs=[img_input], outputs=[stage1_branch1_out, stage1_branch2_out, stage1_branch3_out])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fWQcLqa-8wNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "#import util\n",
        "#from config_reader import config_reader\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from keras.models import load_model\n",
        "import code\n",
        "import copy\n",
        "import scipy.ndimage as sn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "#from model_simulated_RGB101 import get_testing_model_resnet101\n",
        "#from human_seg.human_seg_gt import human_seg_combine_argmax\n",
        "\n",
        "right_part_idx = [2, 3, 4,  8,  9, 10, 14, 16]\n",
        "left_part_idx =  [5, 6, 7, 11, 12, 13, 15, 17]\n",
        "human_part = [0,1,2,4,3,6,5,8,7,10,9,12,11,14,13]\n",
        "human_ori_part = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
        "seg_num = 15\n",
        "\n",
        "#from model_simulated_RGB101 import get_testing_model_resnet101\n",
        "#from human_seg.human_seg_gt import human_seg_combine_argmax\n",
        "\n",
        "\n",
        "right_part_idx = [2, 3, 4,  8,  9, 10, 14, 16]\n",
        "left_part_idx =  [5, 6, 7, 11, 12, 13, 15, 17]\n",
        "human_part = [0,1,2,4,3,6,5,8,7,10,9,12,11,14,13]\n",
        "human_ori_part = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
        "seg_num = 15 # current model supports 15 parts only\n",
        "\n",
        "def recover_flipping_output(oriImg, heatmap_ori_size, paf_ori_size, part_ori_size):\n",
        "\n",
        "    heatmap_ori_size = heatmap_ori_size[:, ::-1, :]\n",
        "    heatmap_flip_size = np.zeros((oriImg.shape[0], oriImg.shape[1], 19))\n",
        "    heatmap_flip_size[:,:,left_part_idx] = heatmap_ori_size[:,:,right_part_idx]\n",
        "    heatmap_flip_size[:,:,right_part_idx] = heatmap_ori_size[:,:,left_part_idx]\n",
        "    heatmap_flip_size[:,:,0:2] = heatmap_ori_size[:,:,0:2]\n",
        "\n",
        "    paf_ori_size = paf_ori_size[:, ::-1, :]\n",
        "    paf_flip_size = np.zeros((oriImg.shape[0], oriImg.shape[1], 38))\n",
        "    paf_flip_size[:,:,ori_paf_idx] = paf_ori_size[:,:,flip_paf_idx]\n",
        "    paf_flip_size[:,:,x_paf_idx] = paf_flip_size[:,:,x_paf_idx]*-1\n",
        "\n",
        "    part_ori_size = part_ori_size[:, ::-1, :]\n",
        "    part_flip_size = np.zeros((oriImg.shape[0], oriImg.shape[1], 15))\n",
        "    part_flip_size[:,:,human_ori_part] = part_ori_size[:,:,human_part]\n",
        "    return heatmap_flip_size, paf_flip_size, part_flip_size\n",
        "\n",
        "def recover_flipping_output2(oriImg, part_ori_size):\n",
        "\n",
        "    part_ori_size = part_ori_size[:, ::-1, :]\n",
        "    part_flip_size = np.zeros((oriImg.shape[0], oriImg.shape[1], 15))\n",
        "    part_flip_size[:,:,human_ori_part] = part_ori_size[:,:,human_part]\n",
        "    return part_flip_size\n",
        "\n",
        "def part_thresholding(seg_argmax):\n",
        "    background = 0.6\n",
        "    head = 0.4\n",
        "    torso = 0.8\n",
        "\n",
        "    rightfoot = 0.3\n",
        "    leftfoot = 0.1\n",
        "    leftthigh = 0.5\n",
        "    rightthigh = 0.3\n",
        "    leftshank = 0.5\n",
        "    rightshank = 0.3\n",
        "    rightupperarm = 0.3\n",
        "    leftupperarm = 0.5\n",
        "    rightforearm = 0.3\n",
        "    leftforearm = 0.5\n",
        "    lefthand = 0.5\n",
        "    righthand = 0.3\n",
        "\n",
        "    part_th = [background, head, torso, leftupperarm ,rightupperarm, leftforearm, rightforearm, lefthand, righthand, leftthigh, rightthigh, leftshank, rightshank, leftfoot, rightfoot]\n",
        "    th_mask = np.zeros(seg_argmax.shape)\n",
        "    for indx in range(15):\n",
        "        part_prediction = (seg_argmax==indx)\n",
        "        part_prediction = part_prediction*part_th[indx]\n",
        "        th_mask += part_prediction\n",
        "\n",
        "    return th_mask\n",
        "\n",
        "\n",
        "def process (input_image, params, model_params):\n",
        "    input_scale = 1.0\n",
        "\n",
        "    oriImg = cv2.imread(input_image)\n",
        "    flipImg = cv2.flip(oriImg, 1)\n",
        "    oriImg = (oriImg / 256.0) - 0.5\n",
        "    flipImg = (flipImg / 256.0) - 0.5\n",
        "    multiplier = [x * model_params['boxsize'] / oriImg.shape[0] for x in params['scale_search']]\n",
        "\n",
        "    seg_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 15))\n",
        "\n",
        "    segmap_scale1 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale2 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale3 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale4 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "\n",
        "    segmap_scale5 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale6 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale7 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "    segmap_scale8 = np.zeros((oriImg.shape[0], oriImg.shape[1], seg_num))\n",
        "\n",
        "    for m in range(len(multiplier)):\n",
        "        scale = multiplier[m]*input_scale\n",
        "        imageToTest = cv2.resize(oriImg, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        pad = [ 0,\n",
        "                0,\n",
        "                (imageToTest.shape[0] - model_params['stride']) % model_params['stride'],\n",
        "                (imageToTest.shape[1] - model_params['stride']) % model_params['stride']\n",
        "              ]\n",
        "\n",
        "        imageToTest_padded = np.pad(imageToTest, ((0, pad[2]), (0, pad[3]), (0, 0)), mode='constant', constant_values=((0, 0), (0, 0), (0, 0)))\n",
        "\n",
        "        input_img = imageToTest_padded[np.newaxis, ...]\n",
        "\n",
        "        print( \"\\tActual size fed into NN: \", input_img.shape)\n",
        "\n",
        "        output_blobs = model.predict(input_img)\n",
        "        seg = np.squeeze(output_blobs[2])\n",
        "        seg = cv2.resize(seg, (0, 0), fx=model_params['stride'], fy=model_params['stride'],\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "        seg = seg[:imageToTest_padded.shape[0] - pad[2], :imageToTest_padded.shape[1] - pad[3], :]\n",
        "        seg = cv2.resize(seg, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        if m==0:\n",
        "            segmap_scale1 = seg\n",
        "        elif m==1:\n",
        "            segmap_scale2 = seg\n",
        "        elif m==2:\n",
        "            segmap_scale3 = seg\n",
        "        elif m==3:\n",
        "            segmap_scale4 = seg\n",
        "\n",
        "\n",
        "    # flipping\n",
        "    for m in range(len(multiplier)):\n",
        "        scale = multiplier[m]\n",
        "        imageToTest = cv2.resize(flipImg, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "        pad = [ 0,\n",
        "                0,\n",
        "                (imageToTest.shape[0] - model_params['stride']) % model_params['stride'],\n",
        "                (imageToTest.shape[1] - model_params['stride']) % model_params['stride']\n",
        "              ]\n",
        "\n",
        "        imageToTest_padded = np.pad(imageToTest, ((0, pad[2]), (0, pad[3]), (0, 0)), mode='constant', constant_values=((0, 0), (0, 0), (0, 0)))\n",
        "        input_img = imageToTest_padded[np.newaxis, ...]\n",
        "        print( \"\\tActual size fed into NN: \", input_img.shape)\n",
        "        output_blobs = model.predict(input_img)\n",
        "\n",
        "        # extract outputs, resize, and remove padding\n",
        "        seg = np.squeeze(output_blobs[2])\n",
        "        seg = cv2.resize(seg, (0, 0), fx=model_params['stride'], fy=model_params['stride'],\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "        seg = seg[:imageToTest_padded.shape[0] - pad[2], :imageToTest_padded.shape[1] - pad[3], :]\n",
        "        seg = cv2.resize(seg, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "        seg_recover = recover_flipping_output2(oriImg, seg)\n",
        "\n",
        "        if m==0:\n",
        "            segmap_scale5 = seg_recover\n",
        "        elif m==1:\n",
        "            segmap_scale6 = seg_recover\n",
        "        elif m==2:\n",
        "            segmap_scale7 = seg_recover\n",
        "        elif m==3:\n",
        "            segmap_scale8 = seg_recover\n",
        "\n",
        "    segmap_a = np.maximum(segmap_scale1,segmap_scale2)\n",
        "    segmap_b = np.maximum(segmap_scale4,segmap_scale3)\n",
        "    segmap_c = np.maximum(segmap_scale5,segmap_scale6)\n",
        "    segmap_d = np.maximum(segmap_scale7,segmap_scale8)\n",
        "    seg_ori = np.maximum(segmap_a, segmap_b)\n",
        "    seg_flip = np.maximum(segmap_c, segmap_d)\n",
        "    seg_avg = np.maximum(seg_ori, seg_flip)\n",
        "\n",
        "\n",
        "    return seg_avg\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the model\n",
        "    keras_weights_file = './weights/model_simulated_RGB_mgpu_scaling_append.0071.h5'\n",
        "    model = get_testing_model_resnet101()\n",
        "    model.load_weights(keras_weights_file)\n",
        "    params, model_params = config_reader()\n",
        "\n",
        "    # Set the scale list (modify as needed)\n",
        "    scale_list = [1.0, 1.5, 2.0]\n",
        "    params['scale_search'] = scale_list\n",
        "\n",
        "    # Set the input and output folders\n",
        "    input_folder = './input'\n",
        "    output_folder = './output'\n",
        "\n",
        "    # Process images in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "            print(input_folder+'/'+filename)\n",
        "            seg = process(input_folder+'/'+filename, params, model_params)\n",
        "            seg_argmax = np.argmax(seg, axis=-1)\n",
        "            seg_max = np.max(seg, axis=-1)\n",
        "            th_mask = part_thresholding(seg_argmax)\n",
        "            seg_max_thres = (seg_max > 0.1).astype(np.uint8)\n",
        "            seg_argmax *= seg_max_thres\n",
        "            seg_canvas = human_seg_combine_argmax(seg_argmax)\n",
        "            cur_canvas = cv2.imread(input_folder+'/'+filename)\n",
        "            #print(cur_canvas.shape)\n",
        "            #plt.imshow(cur_canvas)\n",
        "            #plt.show()\n",
        "            #print(seg_canvas.shape)\n",
        "            #print(np.unique(seg_canvas))\n",
        "            #plt.imshow(seg_canvas)\n",
        "            #plt.show()\n",
        "            canvas = seg_canvas\n",
        "            output_filename = '%s/%s.jpg' % (output_folder, 'seg_' + filename)\n",
        "            cv2.imwrite(output_filename, canvas)\n"
      ],
      "metadata": {
        "id": "TEYcEfL_8onu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXPUcVb9aY48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Yqi4G9sYfJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86_NV73kl5Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8CyJeQv24ct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}